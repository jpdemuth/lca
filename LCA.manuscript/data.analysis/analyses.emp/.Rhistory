foo[1, 2] <- sum(census[2:L,2])
census <- foo
print(census)
}
x <- as.bigq(sum(census[,2]))
y <- sum(as.bigq(census[,2]))
print(x)
print(y)
L <- 19
M <- 100
M <- M-1
foo2 <- census <- matrix(c(1:L, rep(0, L)),L,2)
census[1, 2] <- 1
for(i in 1:M){
foo <- foo2
#print(paste("Month:", i))
for(j in 2:L){
foo[j, 2] <- census[(j-1), 2]
}
foo[1, 2] <- sum(census[2:L,2])
census <- foo
print(census)
}
x <- as.bigq(sum(census[,2]))
y <- sum(as.bigq(census[,2]))
print(x)
print(y)
L <- 16
M <- 83
M <- M-1
foo2 <- census <- matrix(c(1:L, rep(0, L)),L,2)
census[1, 2] <- 1
for(i in 1:M){
foo <- foo2
#print(paste("Month:", i))
for(j in 2:L){
foo[j, 2] <- census[(j-1), 2]
}
foo[1, 2] <- sum(census[2:L,2])
census <- foo
print(census)
}
x <- as.bigq(sum(census[,2]))
y <- sum(as.bigq(census[,2]))
print(x)
print(y)
L <- 3
M <- 6
M <- M-1
foo2 <- census <- matrix(c(1:L, rep(0, L)),L,2)
census[1, 2] <- 1
for(i in 1:M){
foo <- foo2
#print(paste("Month:", i))
for(j in 2:L){
foo[j, 2] <- census[(j-1), 2]
}
foo[1, 2] <- sum(census[2:L,2])
census <- foo
print(census)
}
x <- as.bigq(sum(census[,2]))
y <- sum(as.bigq(census[,2]))
print(x)
print(y)
L <- 20
M <- 96
M <- M-1
foo2 <- census <- list()
census[[1]] <- as.bigq(1)
for(i in 1:M){
foo <- foo2
for(j in 2:L){
foo[[j]] <- census[[j-1]]
}
foo[[1]] <- sum(unlist(census)[2:L]]
census <- foo
L <- 20
M <- 96
M <- M-1
foo2 <- census <- list()
census[[1]] <- as.bigq(1)
for(i in 1:M){
foo <- foo2
for(j in 2:L){
foo[[j]] <- census[[j-1]]
}
foo[[1]] <- sum(unlist(census)[2:L]
census <- foo
}
y <- sum(unlist(census))
print(y)
L <- 20
M <- 96
M <- M-1
foo2 <- census <- list()
census[[1]] <- as.bigq(1)
for(i in 1:M){
foo <- foo2
for(j in 2:L){
foo[[j]] <- census[[j-1]]
}
foo[[1]] <- sum(unlist(census)[2:L])
census <- foo
}
y <- sum(unlist(census))
print(y)
L <- 20
M <- 96
M <- M-1
foo2 <- census <- list()
census[[1]] <- as.bigq(1)
i <- 1
foo <- foo2
j <- 2
foo[[1]] <- 0
for(j in 2:L){
foo[[j]] <- census[[j-1]]
}
foo2 <- census <- list(length=L)
census[[1]] <- as.bigq(1)
for(i in 1:M){
foo <- foo2
foo[[1]] <- 0
for(j in 2:L){
foo[[j]] <- census[[j-1]]
}
foo[[1]] <- sum(unlist(census)[2:L])
census <- foo
}
W <- vector("list", 602)
foo2 <- census <- vector("list", L)
L <- 20
M <- 96
M <- M-1
foo2 <- census <- vector("list", L)
census[[1]] <- as.bigq(1)
for(i in 1:M){
foo <- foo2
foo[[1]] <- 0
for(j in 2:L){
foo[[j]] <- census[[j-1]]
}
foo[[1]] <- sum(unlist(census)[2:L])
census <- foo
}
y <- sum(unlist(census))
print(y)
unlist(census)
unlist(census)[2:L]
census
L <- 20
M <- 96
M <- M-1
foo2 <- census <- vector("list", L)
census[[1]] <- as.bigq(1)
census
foo <- foo2
foo[[1]] <- 0
foo[[1]] <- as.bigq(0)
census
foo
j <- 2
census[[j-1]]
foo[[j]] <- census[[j-1]]
foo
unlist(census)
census[[1]]
census[[2]]
unlist(census)
sum(unlist(census))
census[[1]]
census[[1]]->x
census[[1]]->y
x + y
length(census)
for(i in 1:length(census)){
bar[i] <- census[i]
}
bar <- vector()
for(i in 1:length(census)){
bar[i] <- census[i]
}
bar <- vector()
for(i in 1:length(census)){
bar[i] <- census[[i]]
}
sum(census[1:3])
L <- 20
M <- 96
M <- M-1
foo2 <- census <- vector("list", L)
census[[1]] <- as.bigz(1)
for(i in 1:M){
foo <- foo2
foo[[1]] <- as.bigz(0)
for(j in 2:L){
foo[[j]] <- census[[j-1]]
}
bar <- vector()
for(i in 1:length(census)){
bar[i] <- census[[i]]
}
census <- foo
}
y <- sum(unlist(census))
print(y)
y <- add.bigz(census)
y <- add.bigz(unlist(census))
unlist(census)
37450/2
.2^5
.2^6
99660/2
sqrt(1/2)
1 - .5^2
(1 - .5^2) * (1-.2^2)
(1 - .5^2) * (.2^2)
(.5^2) * (1-.2^2)
(.5^2) * (.2^2)
(1 - .5^2) * (1-.2^2) * 95
(1 - .5^2) * (.2^2) * 38
(.5^2) * (1-.2^2) * 90
(.5^2) * (.2^2) * 33
(1 - .5^2) * (1-.2^2) * 95 +
(1 - .5^2) * (.2^2) * 38 +
(.5^2) * (1-.2^2) * 90 +
(.5^2) * (.2^2) * 33
95*.4
38*.1
90*.4
33*.1
95*.4 +
38*.1 +
90*.4 +
33*.1
91.47-81.1
95-38
57*.2
2*.25*2.5
2*.64*11.4
91.47-20.74
library("evobiR", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("taxize", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("rgbif", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
install.packages("rgbif")
library("taxize", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("rgdal", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
install.packages("rgdal")
library("rgdal", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("taxize", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library("evobiR", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
system.file("3.fasta")
system.file("3.fasta", package="evobiR")
read.fasta(system.file("3.fasta", package='evobiR'))->fii
readFasta(system.file("3.fasta", package='evobiR'))->fii
CalcPopD
read.alignment(system.file("3.fasta", package='evobiR'))->fii
read.alignment(system.file("3.fasta", package='evobiR'), format='fasta')->fii
install.packages("evobiR")
citation(geiger)
citation("geiger")
setwd("~/Desktop/Dropbox/papers/LCA")
library(devtools)
install("SAGA")
library(SAGA)
setwd("~/Desktop/Dropbox/papers/LCA/analyses")
cmat <- read.csv("Cmatrix.mp.csv")
#these are the 8 lines for which we will make data
lines <- c(3, 6, 9, 12, 30, 33, 39, 48)
#these are the composite effects that we will have producing the line means
#  Aa, Ad, Mea, AaAa, AaAd, AdAd
comp.eff <- c(4, 5, 10, 12, 13, 14)
gen.mat <- cmat[lines, comp.eff]
cohorts.me <- list()
cohorts.se <- list()
true.vals <- matrix(0,250,11)
#######
####### Change the value in rep to .25, .5, 1, 2
#######
eff.size <- rep(1, times=250)
for(i in 1:250){
foo <- foo2 <- vector()
true.vals[i, 1:7] <- c(4.58, eff.size[i], eff.size[i], eff.size[i],
eff.size[i], eff.size[i], eff.size[i])
for(j in 1:8){
true.val <- 4.58 + sum(gen.mat[j, ] * c(eff.size[i], eff.size[i],
eff.size[i], eff.size[i],
eff.size[i], eff.size[i]))
# here we draw the cohort mean from a normal distribution with a mean
# equal to the true value and a sd = .087 which is the average across
# all line means in the miller 2003 paper.
cohort.sample <- rnorm(30, mean=true.val, sd=.087)
foo[j] <- mean(cohort.sample)
foo2[j] <- sd(cohort.sample)/sqrt(30)
}
cohorts.me[[i]] <- foo
cohorts.se[[i]] <- foo2
}
# plot the cohorts to make sure the look as expected
plot(x=1,y=1,col="white", ylim=c(0, 10), xlim=c(0,250))
for(i in 1:250){
points(x=rep(i, times=8), y=cohorts.me[[i]], col="red", pch= 19, cex=.3)
}
# now lets evaluate these datasets
est.par <- matrix(,250,11)
max.waic <- names <- true.waic.record <- vector()
variable.imp <- list()
for(i in 1:250){
#here we introduce noise = to ± 5% of mean
obs <- cohorts.me[[i]]
se <- cohorts.se[[i]]
#construct the data matrix for analysis
data <- matrix(c(lines, obs, se), 8, 3)
#fit the models
run <- AnalyzeCrossesMM(data, model.sum=.95, even.sex=F, graph=F)
## these are the par estimates used to calculate % error
est.par[i, 1:11] <- run[[2]][1,]
true.waic <- run[[3]][names(run[[3]]) == "Aa, Mea, AaAd"]
true.waic.record[i] <- true.waic
max.waic[i] <- run[[3]][which.max(run[[3]])]
names[i] <- names(run[[3]][which.max(run[[3]])])
variable.imp[[i]] <- run[[4]]
}
col.id <- vector()
for(i in 1:250){
if(names[i] == "Aa, Mea, AaAd"){
col.id[i] <- "red"
}else{
col.id[i] <- "blue"
}
}
setwd("~/Desktop/Dropbox/papers/LCA")
library(devtools)
install("SAGA")
library(SAGA)
setwd("~/Desktop/Dropbox/papers/LCA/analyses")
cmat <- read.csv("Cmatrix.mp.csv")
#these are the 8 lines for which we will make data
lines <- c(3, 6, 9, 12, 30, 33, 39, 48)
#these are the composite effects that we will have producing the line means
#  Aa, Ad, Mea, AaAa, AaAd, AdAd
comp.eff <- c(4, 5, 10, 12, 13, 14)
gen.mat <- cmat[lines, comp.eff]
cohorts.me <- list()
cohorts.se <- list()
true.vals <- matrix(0,250,11)
#######
####### Change the value in rep to .25, .5, 1, 2
#######
eff.size <- rep(1, times=250)
for(i in 1:250){
foo <- foo2 <- vector()
true.vals[i, 1:7] <- c(4.58, eff.size[i], eff.size[i], eff.size[i],
eff.size[i], eff.size[i], eff.size[i])
for(j in 1:8){
true.val <- 4.58 + sum(gen.mat[j, ] * c(eff.size[i], eff.size[i],
eff.size[i], eff.size[i],
eff.size[i], eff.size[i]))
# here we draw the cohort mean from a normal distribution with a mean
# equal to the true value and a sd = .087 which is the average across
# all line means in the miller 2003 paper.
cohort.sample <- rnorm(30, mean=true.val, sd=.087)
foo[j] <- mean(cohort.sample)
foo2[j] <- sd(cohort.sample)/sqrt(30)
}
cohorts.me[[i]] <- foo
cohorts.se[[i]] <- foo2
}
# plot the cohorts to make sure the look as expected
plot(x=1,y=1,col="white", ylim=c(0, 10), xlim=c(0,250))
for(i in 1:250){
points(x=rep(i, times=8), y=cohorts.me[[i]], col="red", pch= 19, cex=.3)
}
# now lets evaluate these datasets
est.par <- matrix(,250,11)
max.waic <- names <- true.waic.record <- vector()
variable.imp <- list()
for(i in 1:250){
#here we introduce noise = to ± 5% of mean
obs <- cohorts.me[[i]]
se <- cohorts.se[[i]]
#construct the data matrix for analysis
data <- matrix(c(lines, obs, se), 8, 3)
#fit the models
run <- AnalyzeCrossesMM(data, model.sum=.95, even.sex=F, graph=F)
## these are the par estimates used to calculate % error
est.par[i, 1:11] <- run[[2]][1,]
true.waic <- run[[3]][names(run[[3]]) == "Aa, Mea, AaAd"]
true.waic.record[i] <- true.waic
max.waic[i] <- run[[3]][which.max(run[[3]])]
names[i] <- names(run[[3]][which.max(run[[3]])])
variable.imp[[i]] <- run[[4]]
}
col.id <- vector()
for(i in 1:250){
if(names[i] == "Aa, Mea, AaAd"){
col.id[i] <- "red"
}else{
col.id[i] <- "blue"
}
}
glm(data[,2], gen.mat)->foobish
glm(data[,2] ~ as.matrix(gen.mat))->foobish
alias(foobish)
help(alias)
alias(foobish)->foobar
foobar
foobar[1]
foobar[2]
alias(foobish, partial=T)->foobar
foobar
gen.mat
glm(data[,2] ~ as.matrix(gen.mat[,c(6,1:5)]))->foobish
goobish
foobish
glm(data[,2] ~ as.matrix(gen.mat[,c(5:6,1:4)]))->foobish
foobish
glm(data[,2] ~ as.matrix(gen.mat[,c(4:6,1:3)]))->foobish
foobish
glm(data[,2] ~ as.matrix(gen.mat[,c(3:6,1:2)]))->foobish
foobish
glm(data[,2] ~ as.matrix(gen.mat[,c(2:6,1)]))->foobish
foobish
??glm
alias(foobish, partial.pattern =T)
alias(foobish, partial.pattern =T, partial=T)
View(gen.mat)
glm(data[,2] ~ as.matrix(gen.mat))->foobish
glm(data[,2] ~ as.matrix(gen.mat))
glm(data[,2] ~ as.matrix(gen.mat[,6,1:5]))
glm(data[,2] ~ as.matrix(gen.mat[,c(6,1:5)]))
glm(data[,2] ~ as.matrix(gen.mat[,c(5:6,1:4)]))
glm(data[,2] ~ as.matrix(gen.mat[,c(4:6,1:3)]))
glm(data[,2] ~ as.matrix(gen.mat[,c(3:6,1:2)]))
glm(data[,2] ~ as.matrix(gen.mat[,c(2:6,1)]))
glm(data[,2] ~ as.matrix(gen.mat[,]))
foobar <- gen.mat[,c(2,4,6)]
View(foobar)
foobar <- gen.mat[,c(2,4,6,1,3,5)]
View(foobar)
glm(data[,2] ~ as.matrix(gen.mat[,c(2,4,6)]))
foobar <- foobar[,1:3]
View(foobar)
cov(foobar)
View(est.par)
setwd("~/Desktop/Dropbox/papers/LCA/results/simulation.results")
write.csv(est.par, file="6par.est.csv")
variable.imp[[1]]
true.vals
est.par
cohorts.se[[1]]
cohorts.me[[1]]
run[[1]][1]
run[[1]][2]
run[[1]][3]
run[[2]][1]
run[[2]]
var.results <= matrix(,10,2)
var.results <- matrix(,10,2)
var.results <- matrix(,10,251)
var.results[,1] <- variable.imp[[1]][,1]
for(i in 2:251){
var.results[,i] <- variable.imp[[(i-1)]][,2]
}
var.results
write.csv(var.resuts, file="6par.var.imp.csv")
write.csv(var.results, file="6par.var.imp.csv")
run[[2]]
se.results <- matrix(,250,11)
for(i in 1:250){
se.results[i,1:11] <- run[[i]][2,]
}
setwd("~/Desktop/Dropbox/papers/LCA/results/simulation.results")
setwd("~/Desktop/Dropbox/papers/LCA")
library(devtools)
library(plotrix)
install("SAGA")
library(SAGA)
setwd("~/Desktop/Dropbox/papers/LCA/analyses")
cmat <- read.csv("Cmatrix.mp.csv")
#these are the 8 lines for which we will make data
lines <- c(3, 6, 9, 12, 30, 33, 39, 48)
#these are the composite effects that we will have producing the line means
#  Aa, Ad, Mea, AaAa, AaAd, AdAd
comp.eff <- c(4, 5, 10, 12, 13, 14)
gen.mat <- cmat[lines, comp.eff]
cohorts.me <- list()
cohorts.se <- list()
true.vals <- matrix(0,250,11)
#######
####### Change the value in rep to .25, .5, 1, 2
#######
eff.size <- rep(1, times=250)
for(i in 1:250){
foo <- foo2 <- vector()
true.vals[i, 1:7] <- c(4.58, eff.size[i], eff.size[i], eff.size[i],
eff.size[i], eff.size[i], eff.size[i])
for(j in 1:8){
true.val <- 4.58 + sum(gen.mat[j, ] * c(eff.size[i], eff.size[i],
eff.size[i], eff.size[i],
eff.size[i], eff.size[i]))
# here we draw the cohort mean from a normal distribution with a mean
# equal to the true value and a sd = .087 which is the average across
# all line means in the miller 2003 paper.
cohort.sample <- rnorm(30, mean=true.val, sd=.087)
foo[j] <- mean(cohort.sample)
foo2[j] <- sd(cohort.sample)/sqrt(30)
}
cohorts.me[[i]] <- foo
cohorts.se[[i]] <- foo2
}
